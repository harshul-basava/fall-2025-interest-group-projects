{
  "config": {
    "dataset_name": "rotten_tomatoes",
    "model_name": "roberta-base",
    "max_length": 128,
    "num_labels": 2,
    "num_epochs": 3,
    "batch_size": 16,
    "learning_rate_full": 2e-05,
    "learning_rate_lora": 0.0001,
    "lora_rank": 8,
    "lora_alpha_ratio": 2,
    "description": "Quick experiment: Rotten Tomatoes + RoBERTa-base"
  },
  "full_finetuning": {
    "experiment_name": "Full Fine-Tuning",
    "training_time": 115.9722855091095,
    "train_loss": 0.27694927343863823,
    "eval_loss": 0.5004221796989441,
    "eval_accuracy": 0.8864915572232646,
    "total_params": 124647170,
    "trainable_params": 124647170,
    "trainable_percentage": 100.0
  },
  "lora": {
    "experiment_name": "LoRA Fine-Tuning",
    "training_time": 85.63708996772766,
    "train_loss": 0.3342042471213585,
    "eval_loss": 0.31564420461654663,
    "eval_accuracy": 0.8808630393996247,
    "total_params": 126248795,
    "trainable_params": 1603163,
    "trainable_percentage": 1.269844199305031
  },
  "comparison": {
    "speedup": 1.3542296399003475,
    "param_reduction": 77.75077768137113,
    "accuracy_diff": -0.0056285178236398226,
    "accuracy_retention_pct": 99.36507936507935
  }
}